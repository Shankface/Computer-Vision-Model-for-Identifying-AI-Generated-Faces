Text-to-Image Diffusion Models such as DALL-E 2 and Stable Diffusion have become increasingly more robust when it comes to creating realistic photos, including human bodies and faces. These models can be used to edit real photos and videos and create deep fakes, which could lead to an exponential spread of misinformation and the downfall of the integrity of digital media. I designed and implemented a deep learning model leveraging Convolutional Neural Networks to discern between AI-generated and real human faces. The model was trained on real faces along with a custom-made dataset of AI-generated faces made using DALL-E 2 and Stable Diffusion 1.6 and achieved a test accuracy of over 99%.
